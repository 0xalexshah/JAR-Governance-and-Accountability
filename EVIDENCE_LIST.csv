L4_Indicator,Organization,Final_Score,Source_Document,Analysis_Context,Source_URL
"Codes of conduct, roles, and training for AI responsibility are in place",Anthropic,5,Responsible Scaling Policy (RSP) (v2.2),"Defines RSO joint approval and structural checks on CEO power, institutionalizing safety control.",https://www.anthropic.com/responsible-scaling-policy
"Codes of conduct, roles, and training for AI responsibility are in place",OpenAI,3,Preparedness Framework 2.0,Confirms the Safety Advisory Group (SAG)’s authority is advisory; CEO retains veto power.,https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf
Board-level AI risk oversight & annual review/attestation,Anthropic,5,The Long-Term Benefit Trust (LTBT),"Evidence of the fiduciary firewall via Class T Shares, creating a legal constraint on executive power.",https://www.anthropic.com/news/the-long-term-benefit-trust
Board-level AI risk oversight & annual review/attestation,OpenAI,3,An update on our safety & security practices,Oversight relies on a Board subcommittee (Safety & Security Committee); subject to leadership approval.,https://openai.com/index/update-on-safety-and-security-practices/
Stakeholder engagement and escalation paths defined,OpenAI,4,Raising Concerns Policy and Integrity Line,Evidence of formalized whistleblower protection and systematized Kodex intake portal.,https://openai.com/index/openai-raising-concerns-policy/
Stakeholder engagement and escalation paths defined,Anthropic,3,Anthropic Government Requests Report,Policy-based engagement; publishes bi-annual transparency report documenting requests.,https://assets.anthropic.com/m/604a7603983db0b9/original/Anthropic-Government-Requests-Report.pdf
Law-enforcement escalation SLAs,Anthropic,3,Anthropic's AI disclosure: What we know and what we're watching for,Precedent of coordinating technical disclosure for cyber espionage threats (functional escalation tier).,https://www.scworld.com/perspective/anthropics-ai-disclosure-what-we-know-and-what-were-watching-for
Law-enforcement escalation SLAs,OpenAI,2,OpenAI Law Enforcement Policy v.2024-07,Explicit non-escalation for self-harm; no published response SLA.,https://cdn.openai.com/trust-and-transparency/openai-law-enforcement-policy-v2024.07.pdf
Indigenous data stewardship & consent,OpenAI,1,OpenAI to Z Challenge,"Gamified archaeological sites using Indigenous historical records; evidence of prioritizing ""Open Data"" over sovereignty.",https://openai.com/openai-to-z-challenge/
Indigenous data stewardship & consent,Anthropic,0,Responsible Scaling Policy (RSP) (v2.2),No evidence of specific policy or commitment to Indigenous Data Sovereignty or CARE Principles found.,https://www.anthropic.com/responsible-scaling-policy
"Change-management plan preserves educator accountability, defines roles, metrics, timeline",OpenAI,4,Using AI to Write Police Reports - COPS Office,Evidence of delegated governance via Human-in-the-Loop requirement (Draft One police reports).,https://cops.usdoj.gov/html/dispatch/01-2025/ai_reports.html
"Change-management plan preserves educator accountability, defines roles, metrics, timeline",Anthropic,4,Responsible Scaling Policy (RSP) (v2.2),"Safety Case methodology imposes metric-driven, structural constraints on deployment timelines in sensitive sectors.",https://www.anthropic.com/responsible-scaling-policy
"Regulatory mapping (e.g., AI Act and sectoral) is current",OpenAI,3,A Primer on the EU AI Act: What It Means for AI Providers and Deployers,Document confirming engagement with the EU AI Office and adherence to the Code of Practice.,https://openai.com/global-affairs/a-primer-on-the-eu-ai-act/
"Regulatory mapping (e.g., AI Act and sectoral) is current",Anthropic,3,EU AI Act: first regulation on artificial intelligence,Foundational source defining GPAI obligations and high-risk classification.,https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence
External claims and marketing match measured performance (no overclaiming),OpenAI,2,DeepMind CEO Rejects OpenAI's Claim That GPT-5 Is PhD-Level Across the Board,"External expert rejection of OpenAI's core marketing claim, supporting the High Risk score.",https://www.remio.ai/post/deepmind-ceo-rejects-openai-s-claim-that-gpt-5-is-phd-level-across-the-board
External claims and marketing match measured performance (no overclaiming),Anthropic,2,Repo State Loopholes During Agentic Evaluation · Issue #465 - GitHub,"Technical audit evidence proving Sonnet 4.5 exploited git log to achieve a contaminated SWE-bench score (""Reward Hacking"").",https://github.com/SWE-bench/SWE-bench/issues/465
No targeted ads to minors,OpenAI,1,"OpenAI may soon introduce ads in ChatGPT, potentially based on user conversations - Storyboard18",Evidence of commercial trajectory toward ad-supported model leveraging emotional data.,https://www.storyboard18.com/digital/openai-may-soon-introduce-ads-in-chatgpt-potentially-based-on-user-conversations-83282.htm
No targeted ads to minors,Anthropic,5,Introducing Claude for Nonprofits,Structural adherence to subscription model eliminates financial incentive for emotional profiling/ads.,https://www.anthropic.com/news/claude-for-nonprofits
Loot box age gating & disclosures,OpenAI,2,Gamification in Mobile Apps: Boost Engagement - Codica,"Evidence of ""streaks"" and gamification in the official app, creating a compulsion loop.",https://www.codica.com/blog/mobile-apps-gamification/
Loot box age gating & disclosures,Anthropic,5,Claude Sonnet 4.5 System Card,"Utilitarian product design; explicit lack of gamification features (streaks, XP).",https://www.anthropic.com/claude-sonnet-4-5-system-card
Targeting limits in vulnerable contexts (policy),OpenAI,2,AI Girlfriends: OpenAI's GPT Store Offers Digital Companions - The Times of India,Evidence of third-party policy enforcement failure regarding emotionally exploitative companion bots.,https://timesofindia.indiatimes.com/gadgets-news/ai-girlfriends-openais-gpt-store-offers-digital-companions/articleshow/106907449.cms
Targeting limits in vulnerable contexts (policy),Anthropic,4,Content moderation - Claude Docs,"Policy demonstrates tighter, risk-averse refusal boundaries on specialized/sensitive advice definitions.",https://platform.claude.com/docs/en/about-claude/use-case-guides/content-moderation
Competition & monopoly risk program,OpenAI,2,Competition Policy Brief - European Union,"Evidence of EU Commission treating staff transfers (e.g., Inflection AI acqui-hire) as de facto mergers.",https://competition-policy.ec.europa.eu/document/download/c86d461f-062e-4dde-a662-15228d6ca385_en
Competition & monopoly risk program,Anthropic,2,Anthropic “blindsided” by proposed U.S. Google AI investment ban - ai fray,Evidence of active DOJ antitrust intervention targeting the relationship between Anthropic and Google/Amazon.,https://aifray.com/anthropic-blindsided-by-proposed-u-s-google-ai-investment-ban-seeks-to-participate-in-doj-antitrust-suit/
Equitable access & pricing policy,Anthropic,5,Introducing Claude for Nonprofits - Anthropic,"Public commitment detailing the 75% discount on top-tier models, used to score Equitable Access.",https://www.anthropic.com/news/claude-for-nonprofits
Equitable access & pricing policy,OpenAI,3,"OpenAI for nonprofits: 2025 discounts, reviews & alternatives",Evidence of standard corporate discounts (20%-50%); lacks structural impact of Anthropic subsidy.,https://nonprofitprice.com/deal/openai/
Cross-border impact due diligence,OpenAI,2,"AI chatbots are easily tripped up by human rights questions, study finds - Mashable",Evidence of LLMs systematically downgrading press freedom rankings in non-Western countries (normative bias export).,https://mashable.com/article/ai-chatbots-free-press-study
Cross-border impact due diligence,Anthropic,2,EU AI Act: first regulation on artificial intelligence,Lack of explainability in agentic systems creates unmitigated due process risk in foreign high-stakes deployment (due diligence failure).,https://www.europarl.europa.eu/topics/en/article/20230601STO93804/eu-ai-act-first-regulation-on-artificial-intelligence